{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f784abf",
   "metadata": {},
   "source": [
    "# Unparameterized K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636360e",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10fe8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c83530",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90feb3a",
   "metadata": {},
   "source": [
    "Data is from 2009-2010 season. 998 total observations consisting of 39 variables. Among the variables, 1 is a binary win/loss variable stating whether the home team won or lost the given game. The remaining 38 variables are broken down into team averages and team performance metrics. There are 34 variables referring to team averages (17 for home, 17 for away). Team averages are calculated from the teams last 10 games. \n",
    "\n",
    "So for the 11th game of the season, team average variables will be the averaged box score stats from games 1-10. For the 12th, team average variables will be calculated from 2-11. And so on. In doing so, this leaves the first 10 games unpredictable, as one can not take average of last 10 games.\n",
    "\n",
    "The team metric variables consist of ELO, which is a continous metric that defines overall team strength. A team that is conistently good will show high levels of ELO. The idea is that a team gets ELO points for good performances. A playoff win will equate to more ELO points than a win in game 4 of the season. Blowouts, upsets, and road victories receive more points as well. Along with ELO, teams winning percentage in the last 10 games is also considered and recorded as a variable. This well help give a feel of overall recent performance.\n",
    "\n",
    "The remaining variables consist of 2 dummy variables specifying whether each team is playing in a back to back. For instance, if Cleveland is playing Miami on December 25th, and Cleveland played last night on December 24th, they will receive a 1 for the back to back variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4979c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/johnoliver/Downloads/grad-nba-wins/data/mod_data')\n",
    "# data from 2010\n",
    "df10 = pd.read_csv(\"mod10.csv\")\n",
    "# get rid of first variable (unique identifier)\n",
    "df10 = df10.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5105d",
   "metadata": {},
   "source": [
    "### Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e271935",
   "metadata": {},
   "source": [
    "Data is split into training (70%) and testing (30%) data. Home win is predicted by the 38 average and team metric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5e938c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and y variables\n",
    "feature_cols = [\"h_avg_points\",\"a_avg_points\",\"h_avg_fg\",\"a_avg_fg\",\n",
    "                \"h_avg_fga\",\"a_avg_fga\",\"h_avg_3p\",\"a_avg_3p\",\n",
    "                \"h_avg_3pa\",\"a_avg_3pa\",\"h_avg_ft\",\"a_avg_ft\",\n",
    "                \"h_avg_orb\",\"a_avg_orb\",\"h_avg_drb\" ,\"a_avg_drb\",\n",
    "                \"h_avg_ast\",\"a_avg_ast\",\"h_avg_stl\", \"a_avg_stl\", \n",
    "                \"h_avg_blk\",\"a_avg_blk\",\"h_avg_tov\",\"a_avg_tov\",\n",
    "                \"h_avg_pf\",\"a_avg_pf\" ,\"h_avg_tsp\",  \"a_avg_tsp\",\n",
    "                \"h_avg_ortg\",\"a_avg_ortg\",\"h_avg_drtg\",\"a_avg_drtg\",\n",
    "                \"h_win_perc\",\"a_win_perc\",\"h_back\",\"a_back\",\n",
    "                \"home_elo\", \"away_elo\"]\n",
    "\n",
    "X = df10[feature_cols]\n",
    "Y = df10.win_status\n",
    "\n",
    "# split data into training and testing\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,\n",
    "                                               test_size=0.3,\n",
    "                                               random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ae181",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# set up k fold cross validation \n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train,y_train)\n",
    "lr_scores = cross_val_score(lr_model, X_test, y_test,\n",
    "                            scoring = 'accuracy', cv = cv,\n",
    "                            n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cad9094b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.679 (0.066)\n",
      "Nonparameterized Run Time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Test Accuracy: %.3f (%.3f)' % (mean(lr_scores), std(lr_scores)))\n",
    "print(\"Nonparameterized Run Time: 2.52 s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75ff0a",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dabd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31322c66",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706d827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e470787",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29573c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79b06fe",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c848974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
